# Postgres settings (must match https://github.com/docker-library/docs/blob/master/postgres/README.md)
# Required for the official postgres image when POSTGRES_HOST_AUTH_METHOD is not set to "trust"
# Never leave POSTGRES_PASSWORD empty in production
POSTGRES_DB=n8n
POSTGRES_USER=n8n
POSTGRES_PASSWORD=n8n

# Database connection for n8n (maps to DB_* envs n8n expects)
DB_TYPE=postgresdb
DB_POSTGRESDB_HOST=postgres
DB_POSTGRESDB_PORT=5432
DB_POSTGRESDB_DATABASE=${POSTGRES_DB}
DB_POSTGRESDB_USER=${POSTGRES_USER}
DB_POSTGRESDB_SCHEMA=public
DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}

# n8n server configuration
# Set these as needed; defaults are convenient for local development
N8N_BASIC_AUTH_ACTIVE=true
N8N_BASIC_AUTH_USER=admin
N8N_BASIC_AUTH_PASSWORD=admin
N8N_HOST=0.0.0.0
N8N_PORT=5678
N8N_PROTOCOL=http
WEBHOOK_URL=http://localhost:5678/

# n8n runtime / environment controls
# Enforce secure settings file permissions (true/false)
# Set to false to avoid permission issues with Docker volumes
N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=false
# Enable diagnostics for better error logging
N8N_DIAGNOSTICS_ENABLED=true
# Binary data mode for file handling
N8N_DEFAULT_BINARY_DATA_MODE=filesystem
# Enable n8n runners (true/false)
N8N_RUNNERS_ENABLED=true
# Node environment
NODE_ENV=production
# Timezone settings
GENERIC_TIMEZONE=America/Sao_Paulo
TZ=America/Sao_Paulo

# Community nodes configuration
# Enable installation of community nodes via n8n UI
N8N_COMMUNITY_PACKAGES_ENABLED=true

# Telegram Bot Tokens
# Get these from @BotFather on Telegram
TELEGRAM_BOT_TOKEN_1=your_first_bot_token_here
TELEGRAM_BOT_TOKEN_2=your_second_bot_token_here
TELEGRAM_BOT_TOKEN_3=your_third_bot_token_here

# OpenAI API Configuration
# Get your API key from https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
# Optional: Use a different OpenAI-compatible endpoint
# OPENAI_API_BASE=https://api.openai.com/v1

# Google Gemini (optional)
# GEMINI_API_KEY: API key or service account credential for Gemini
# GEMINI_API_BASE: optional custom base URL for Gemini-compatible APIs
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_API_BASE=

# Deepseek (optional)
# DEEPSEEK_API_KEY: API key for Deepseek
# DEEPSEEK_API_BASE: optional base URL for Deepseek API
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_API_BASE=

# LLM provider selection
# Set to one of: openai, gemini, deepseek
LLM_PROVIDER=openai

# Default model for provider
LLM_MODEL=gpt-3.5-turbo

# Fallback LLM configuration
# If the primary provider fails, the workflow can use these values
FALLBACK_LLM_PROVIDER=
FALLBACK_LLM_MODEL=
